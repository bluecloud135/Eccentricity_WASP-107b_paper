{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4302b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'font.family': 'serif',\n",
    "    'axes.linewidth': 1.4,\n",
    "    'xtick.major.size': 8,\n",
    "    'ytick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.minor.size': 4,\n",
    "    'axes.labelpad': 8,\n",
    "    'lines.linewidth': 1.8,\n",
    "    'lines.markersize': 10,\n",
    "    'axes.titlepad': 15,\n",
    "    'legend.frameon': True,\n",
    "    'legend.framealpha': 0.8,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.minor.width': 1.5,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7647c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPaths(indir):\n",
    "    csvs = glob(indir+'*/'+'*fitparams*.csv')\n",
    "    paths = sorted(csvs)\n",
    "    return paths\n",
    "\n",
    "def getTime(indir,name,period,IDs):\n",
    "    paths = getPaths(indir)\n",
    "    median = []\n",
    "    up = []\n",
    "    down = []\n",
    "    ini_path = []\n",
    "    for path in paths:\n",
    "        if '.csv' in path:\n",
    "            now = pd.read_csv(path)\n",
    "            now.set_index('Parameter',inplace=True)\n",
    "            t0_name = 't0'\n",
    "        else:\n",
    "            ValueError('The file format is not recognized. Please ensure the file is a valid CSV or has the correct format.')\n",
    "\n",
    "        median.append(float(now.loc[t0_name,'50th']))\n",
    "        up.append(float(now.loc[t0_name,'+1sigma']))\n",
    "        down.append(abs(float(now.loc[t0_name,'-1sigma'])))\n",
    "        ini_path.append(path)\n",
    "    time = pd.DataFrame({'name':name,'median':median, '+1 sigma':up, '-1 sigma':down})\n",
    "    # time['median'] += 2400000.5\n",
    "    time['median'] = [x+2400000.5 if x<2400000.5 else x for x in time['median']]\n",
    "    time.sort_values(['median'])\n",
    "    time.index = range(len(time))\n",
    "    epoch = round((time['median']-time['median'].min())/period)\n",
    "    time['epoch'] = [int(x) for x in epoch]\n",
    "    time['ID'] = IDs\n",
    "    time['path'] = ini_path\n",
    "    # time.to_csv(indir+'time.csv', index=False)\n",
    "    # time.to_latex(indir+'time.tex', columns=['median','+1 sigma','-1 sigma','ID'], index=False, float_format=\"%.7f\")\n",
    "    return time\n",
    "\n",
    "def binData(data, nbin=100, err=False):\n",
    "    newdata = np.array(data[:nbin*int(len(data)/nbin)])\n",
    "    binned = np.nanmean(newdata.reshape(nbin, -1), axis=1)\n",
    "    if err:\n",
    "        binned /= np.sqrt(int(len(data)/nbin)-1)\n",
    "    return binned\n",
    "\n",
    "def getRps(indir,name,period,IDs):\n",
    "    paths = getPaths(indir)\n",
    "    median = []\n",
    "    up = []\n",
    "    down = []\n",
    "    ini_path = []\n",
    "    for path in paths:\n",
    "        if '.csv' in path:\n",
    "            now = pd.read_csv(path)\n",
    "            now.set_index('Parameter',inplace=True)\n",
    "            t0_name = 'rp'\n",
    "        else:\n",
    "            now = pd.read_csv(path,sep=r'\\t\\s+', names=['Parameter','50th','+1sigma','-1sigma'], engine='python',skiprows=1)\n",
    "            now.set_index('Parameter',inplace=True)\n",
    "            now.index = [x.strip(' ') for x in now.index]\n",
    "            t0_name = 'rp_p1'\n",
    "\n",
    "        median.append(float(now.loc[t0_name,'50th']))\n",
    "        up.append(float(now.loc[t0_name,'+1sigma']))\n",
    "        down.append(abs(float(now.loc[t0_name,'-1sigma'])))\n",
    "        ini_path.append(path)\n",
    "    rps = pd.DataFrame({'name':name,'median':median, '+1 sigma':up, '-1 sigma':down})\n",
    "    rps.sort_values(['median'])\n",
    "    rps.index = range(len(rps))\n",
    "    epoch = round((rps['median']-rps['median'].min())/period)\n",
    "    rps['epoch'] = [int(x) for x in epoch]\n",
    "    rps['ID'] = IDs\n",
    "    rps['path'] = ini_path\n",
    "    # rps.to_csv(indir+'rps.csv', index=False)\n",
    "    # rps.to_latex(indir+'rps.tex', columns=['median','+1 sigma','-1 sigma','ID'], index=False, float_format=\"%.7f\")\n",
    "    return rps\n",
    "\n",
    "\n",
    "def plotLightCurveAdvanced(axes, nbin, t0s, datas, ids, step=0.02):\n",
    "    ax, ax1 = axes\n",
    "    # fig, (ax, ax1) = plt.subplots(1,2, figsize=(24, 12), sharey=True)\n",
    "    offset = 0\n",
    "    first = True  # Flag for first iteration\n",
    "    xpos = min([min(data['t']) for data in datas]) * 0.99\n",
    "    \n",
    "    for t0, data, id in zip(t0s, datas, ids):\n",
    "        center = data['model'].max() - 1\n",
    "        data['relative flux'] -= center\n",
    "        data['model'] -= center\n",
    "        \n",
    "        labels = {\n",
    "            'binned': 'Binned Data' if first else None,\n",
    "            'unbinned': 'Unbinned Data' if first else None,\n",
    "            'model': 'Best-fit Model' if first else None\n",
    "        }\n",
    "        labels_residuals = {\n",
    "            'binned': 'Binned Residuals' if first else None,\n",
    "            'unbinned': 'Unbinned Residuals' if first else None,\n",
    "        }\n",
    "        binned_flux = binData(data['relative flux'] + offset, nbin)\n",
    "        binned_t = binData(data['t'], nbin)\n",
    "        binned_residuals = binData(data['residuals'], nbin)  # No offset for residuals\n",
    "        binned_error = binData(data['error'], nbin, err=True)\n",
    "        \n",
    "        ax.errorbar(binned_t, binned_flux, yerr=binned_error, ms=10, fmt='o',\n",
    "                    color='deepskyblue', ecolor='deepskyblue', mec='deepskyblue', \n",
    "                    zorder=5, label=labels['binned'])\n",
    "        ax.errorbar(data['t'], data['relative flux'] + offset, yerr=data['error'], ms=10, fmt='o',\n",
    "                    color='white', ecolor='lightskyblue', mec='lightskyblue', \n",
    "                    alpha=0.5, zorder=2, label=labels['unbinned'])\n",
    "        ax.plot(data['t'], data['model'] + offset, color='dimgray', \n",
    "                zorder=10, label=labels['model'])\n",
    "        \n",
    "        ax1.errorbar(binned_t, binned_residuals + offset +1, yerr=binned_error, ms=10, fmt='o',\n",
    "                     color='deepskyblue', ecolor='deepskyblue', mec='deepskyblue', \n",
    "                     zorder=5, label=labels_residuals['binned'])\n",
    "        ax1.errorbar(data['t'], data['residuals'] + offset +1, yerr=data['error'], ms=10, fmt='o',\n",
    "                     color='white', ecolor='lightskyblue', mec='lightskyblue', \n",
    "                     alpha=0.5, zorder=2, label=labels_residuals['unbinned'])\n",
    "        ax1.plot(data['t'], [offset+1] * len(data['t']), color='dimgray', zorder=10)  # Zero line\n",
    "        \n",
    "        ypos = np.mean(np.sort(data['relative flux'])[:int(len(data['relative flux'])/10)]) + 0.55*step + offset    # TESS\n",
    "        # ypos = np.mean(np.sort(data['relative flux'])[:int(len(data['relative flux'])/10)]) + 0.7*step + offset    # JWST\n",
    "        ax.text(xpos, ypos, f'{id}\\n$t_0 =${t0:.5f}', fontsize=20, \n",
    "                ha='left', va='top')\n",
    "        \n",
    "        first = False  # Disable labels for subsequent datasets\n",
    "        offset += step * 1.5\n",
    "\n",
    "def getLightCurveData(indir,t0):\n",
    "    files = glob(indir+'*')\n",
    "    for file in files:\n",
    "        if '.txt' in file:\n",
    "            white = pd.read_csv(file,comment='#',sep=' ')\n",
    "    data = pd.DataFrame({'time':white['time'],'relative flux':white['lcdata'],'error':white['lcerr'],'model':white['model']})\n",
    "    center = data['model'].max()-1\n",
    "    data['relative flux'] -= center\n",
    "    data['model'] -= center\n",
    "    data['residuals'] = (data['relative flux'] - data['model'])\n",
    "    # data['t'] = (data['time']-t0+2400000.5)*24\n",
    "    if np.min(data['time'])>2400000.5:\n",
    "        data['t'] = (data['time']-t0)*24\n",
    "    else:\n",
    "        data['t'] = (data['time']-t0+2400000.5)*24\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a922b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = ['jwst', 'tess', 'hst']\n",
    "p = 'WASP-107b'\n",
    "nbin = 50\n",
    "fig, axes = plt.subplots(3,2, figsize=(24, 24),height_ratios=[5,2,2] , sharey='row')\n",
    "\n",
    "for i, ins in enumerate(instruments):\n",
    "    indir = f'wasp-107b/{ins}/'\n",
    "    if ins != 'hst':\n",
    "        with open(f\"init_{ins}.yaml\", \"r\") as f:\n",
    "            init = yaml.safe_load(f)\n",
    "        name = init[p]['name']\n",
    "        period = init[p]['period']\n",
    "        IDs = init[p]['IDs']\n",
    "        ins_name = init[p]['instrument']\n",
    "        labels = [f'{id}-{ins}' for id, ins in zip(IDs, ins_name)]\n",
    "        time = getTime(indir, name, period, IDs)\n",
    "        # time.to_csv(indir+'time.csv', index=False)\n",
    "\n",
    "        rps = getRps(indir, name, period, IDs)\n",
    "        step = np.mean(rps['median'])**2\n",
    "        datas  =[]\n",
    "        t0s = []\n",
    "        ids = []\n",
    "\n",
    "        for dir, t0, id in zip(['/'.join(s.split('/')[:-1])+'/' for s in time['path']], time['median'], time['ID']):\n",
    "            datas.append(getLightCurveData(dir,t0))    \n",
    "            t0s.append(t0)\n",
    "            ids.append(id)\n",
    "\n",
    "        \n",
    "        plotLightCurveAdvanced(axes[i], nbin=nbin, t0s=t0s, datas=datas, ids=labels, step=step)\n",
    "        ax, ax1 = axes[i]\n",
    "        ax.set_xlabel('Time from Transit Midpoint [hrs]', fontsize=28)\n",
    "        \n",
    "        ax1.set_xlabel('Time from Transit Midpoint [hrs]', fontsize=28)\n",
    "    else:\n",
    "        ax, ax1 = axes[i]\n",
    "        ids = ['14916', '14915']\n",
    "        t0s = []\n",
    "        datas = []\n",
    "        model_datas = []\n",
    "        for id in ids:\n",
    "            model_data = pd.read_csv(f'{indir}lc{id}.csv')\n",
    "            now = np.load(f'{indir}{id}fitting_results.pickle', allow_pickle=True)\n",
    "            t0 = now['lightcurves']['white']['parameters_final'][-1]\n",
    "            t0s.append(t0)\n",
    "            phase = now['lightcurves']['white']['output_time_series']['phase']\n",
    "            t = (now['lightcurves']['white']['input_time_series']['bjd_tdb'] - t0)*24\n",
    "            full_model = now['lightcurves']['white']['output_time_series']['full_model']\n",
    "            full_residuals = now['lightcurves']['white']['output_time_series']['full_residuals']\n",
    "            systematics = now['lightcurves']['white']['output_time_series']['systematics']\n",
    "            detrended_lc = now['lightcurves']['white']['output_time_series']['detrended_lc']\n",
    "            transit = now['lightcurves']['white']['output_time_series']['transit']\n",
    "            residuals = now['lightcurves']['white']['output_time_series']['residuals']\n",
    "\n",
    "            data = pd.DataFrame({'t':t,'normalized flux':detrended_lc,'residuals':residuals,'model':transit})\n",
    "            datas.append(data)\n",
    "\n",
    "            func = np.poly1d(np.polyfit(phase, t, 1))\n",
    "            model_data['t'] = func(model_data['phase'])\n",
    "            model_datas.append(model_data)\n",
    "            \n",
    "        xpos = min([min(data['t']) for data in datas]) * 0.99\n",
    "        step = 0.02\n",
    "        offset = 0\n",
    "        first = True\n",
    "\n",
    "        for t0, data, id, mdata in zip(t0s, datas, ids, model_datas):\n",
    "\n",
    "            # center = data['model'].max() - 1\n",
    "            # data['normalized flux'] -= center\n",
    "            # data['model'] -= center\n",
    "            # ax.plot(data['t'], data['model'] + offset, color='dimgray', \n",
    "            #         zorder=10, label='Best-fit Model' if first else None)\n",
    "            ax.plot(mdata['t'], mdata['flux_fitted'] + offset, color='dimgray',\n",
    "                    zorder=10, label='Best-fit Model' if first else None)\n",
    "            ax.scatter(data['t'], data['normalized flux'] + offset, color='deepskyblue', alpha=0.8, s=120, label='Detrended Data' if first else None)\n",
    "            \n",
    "            ax1.scatter(data['t'], data['residuals'] + offset +1, color='deepskyblue', alpha=0.8, s=120)\n",
    "\n",
    "            ax1.plot(data['t'], [offset+1] * len(data['t']), color='dimgray', zorder=10)  # Zero line\n",
    "\n",
    "            ypos = np.mean(np.sort(data['normalized flux'])[:int(len(data['normalized flux'])/10)]) + 0.55*step + offset    # TESS\n",
    "            ax.text(xpos, ypos, f'{id}-HST\\n$t_0 =${t0:.5f}', fontsize=20, \n",
    "                    ha='left', va='top')\n",
    "            \n",
    "            first = False  # Disable labels for subsequent datasets\n",
    "            offset += step * 1.5\n",
    "\n",
    "        ax.set_xlabel('Time from Transit Midpoint [hrs]', fontsize=28)\n",
    "        ax1.set_xlabel('Time from Transit Midpoint [hrs]', fontsize=28)\n",
    "        # ax.set_xlabel('Phase', fontsize=28)\n",
    "        # ax1.set_xlabel('Phase', fontsize=28)\n",
    "    ax.legend(loc='lower right', fontsize=20, frameon=False)\n",
    "    ax.set_ylabel('Relative Flux', fontsize=28)\n",
    "    ax.tick_params(direction='in', which='both', labelsize=24)\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "\n",
    "    ax1.tick_params(direction='in', which='both', labelsize=24)\n",
    "    ax1.minorticks_on()\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "# fig.suptitle(f'White Light Curves and Residuals of {p}', fontsize=36, y=0.98)\n",
    "plt.tight_layout()\n",
    "suffix = ''\n",
    "fig.savefig('white_lightcurves_with_residuals_combined.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "fig.savefig('white_lightcurves_with_residuals_combined.pdf', \n",
    "            bbox_inches='tight')\n",
    "fig.savefig('white_lightcurves_with_residuals_transparent_combined.pdf', \n",
    "            transparent=True, bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
